{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-13T20:49:36.867210Z","iopub.execute_input":"2023-06-13T20:49:36.867465Z","iopub.status.idle":"2023-06-13T20:49:36.879384Z","shell.execute_reply.started":"2023-06-13T20:49:36.867441Z","shell.execute_reply":"2023-06-13T20:49:36.878449Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ndata_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:36.885034Z","iopub.execute_input":"2023-06-13T20:49:36.886367Z","iopub.status.idle":"2023-06-13T20:49:36.954214Z","shell.execute_reply.started":"2023-06-13T20:49:36.886341Z","shell.execute_reply":"2023-06-13T20:49:36.953277Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(data_train.shape)\nprint(data_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:36.956246Z","iopub.execute_input":"2023-06-13T20:49:36.956578Z","iopub.status.idle":"2023-06-13T20:49:36.961791Z","shell.execute_reply.started":"2023-06-13T20:49:36.956547Z","shell.execute_reply":"2023-06-13T20:49:36.960784Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(7613, 5)\n(3263, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"data_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:36.963277Z","iopub.execute_input":"2023-06-13T20:49:36.963977Z","iopub.status.idle":"2023-06-13T20:49:36.984101Z","shell.execute_reply.started":"2023-06-13T20:49:36.963946Z","shell.execute_reply":"2023-06-13T20:49:36.983112Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:36.985501Z","iopub.execute_input":"2023-06-13T20:49:36.985840Z","iopub.status.idle":"2023-06-13T20:49:36.995721Z","shell.execute_reply.started":"2023-06-13T20:49:36.985799Z","shell.execute_reply":"2023-06-13T20:49:36.994573Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import re,string\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:36.999044Z","iopub.execute_input":"2023-06-13T20:49:36.999763Z","iopub.status.idle":"2023-06-13T20:49:38.669831Z","shell.execute_reply.started":"2023-06-13T20:49:36.999730Z","shell.execute_reply":"2023-06-13T20:49:38.668889Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def clean_data(tweet):\n    tweet = tweet.lower()\n    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\",\"\",tweet)\n    tweet = tweet.translate(str.maketrans(\"\",\"\",string.punctuation))\n    tweet = re.sub(r\"\\d+\",\"\",tweet)\n    tokens = word_tokenize(tweet)\n    clena_tweets = \" \".join(tokens)\n    return clena_tweets","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:38.674530Z","iopub.execute_input":"2023-06-13T20:49:38.676797Z","iopub.status.idle":"2023-06-13T20:49:38.684261Z","shell.execute_reply.started":"2023-06-13T20:49:38.676770Z","shell.execute_reply":"2023-06-13T20:49:38.683396Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"radom_tweet = data_train[\"text\"][5]\nradom_tweet","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:38.688369Z","iopub.execute_input":"2023-06-13T20:49:38.688653Z","iopub.status.idle":"2023-06-13T20:49:38.695566Z","shell.execute_reply.started":"2023-06-13T20:49:38.688631Z","shell.execute_reply":"2023-06-13T20:49:38.694505Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires'"},"metadata":{}}]},{"cell_type":"code","source":"cleaned_tweet = clean_data(radom_tweet)\ncleaned_tweet","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:38.697228Z","iopub.execute_input":"2023-06-13T20:49:38.697870Z","iopub.status.idle":"2023-06-13T20:49:38.722047Z","shell.execute_reply.started":"2023-06-13T20:49:38.697834Z","shell.execute_reply":"2023-06-13T20:49:38.721197Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'rockyfire update california hwy closed in both directions due to lake county fire cafire wildfires'"},"metadata":{}}]},{"cell_type":"code","source":"data_train[\"cleaned_tweet\"] = data_train[\"text\"].apply(lambda x:clean_data(x))\ndata_test[\"cleaned_tweet\"] = data_test[\"text\"].apply(lambda x:clean_data(x))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:38.723301Z","iopub.execute_input":"2023-06-13T20:49:38.723786Z","iopub.status.idle":"2023-06-13T20:49:42.125118Z","shell.execute_reply.started":"2023-06-13T20:49:38.723756Z","shell.execute_reply":"2023-06-13T20:49:42.124145Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(data_train.head())\nprint(data_test.head())","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:42.126588Z","iopub.execute_input":"2023-06-13T20:49:42.127112Z","iopub.status.idle":"2023-06-13T20:49:42.140541Z","shell.execute_reply.started":"2023-06-13T20:49:42.127079Z","shell.execute_reply":"2023-06-13T20:49:42.139384Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target                                      cleaned_tweet  \n0       1  our deeds are the reason of this earthquake ma...  \n1       1              forest fire near la ronge sask canada  \n2       1  all residents asked to shelter in place are be...  \n3       1  people receive wildfires evacuation orders in ...  \n4       1  just got sent this photo from ruby alaska as s...  \n   id keyword location                                               text  \\\n0   0     NaN      NaN                 Just happened a terrible car crash   \n1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n\n                                       cleaned_tweet  \n0                 just happened a terrible car crash  \n1  heard about earthquake is different cities sta...  \n2  there is a forest fire at spot pond geese are ...  \n3              apocalypse lighting spokane wildfires  \n4         typhoon soudelor kills in china and taiwan  \n","output_type":"stream"}]},{"cell_type":"code","source":"train_tweets = data_train.cleaned_tweet.values\ntest_tweets = data_test.cleaned_tweet.values\ntrain_targets = data_train.target.values","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:42.146063Z","iopub.execute_input":"2023-06-13T20:49:42.146712Z","iopub.status.idle":"2023-06-13T20:49:42.152647Z","shell.execute_reply.started":"2023-06-13T20:49:42.146681Z","shell.execute_reply":"2023-06-13T20:49:42.151427Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n\nword_tokenizer = Tokenizer()\nword_tokenizer.fit_on_texts(train_tweets)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:42.154116Z","iopub.execute_input":"2023-06-13T20:49:42.154922Z","iopub.status.idle":"2023-06-13T20:49:48.637310Z","shell.execute_reply.started":"2023-06-13T20:49:42.154892Z","shell.execute_reply":"2023-06-13T20:49:48.636345Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab_lenght = len(word_tokenizer.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:48.639041Z","iopub.execute_input":"2023-06-13T20:49:48.639783Z","iopub.status.idle":"2023-06-13T20:49:48.645336Z","shell.execute_reply.started":"2023-06-13T20:49:48.639749Z","shell.execute_reply":"2023-06-13T20:49:48.644334Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def emd(corpus):\n    return word_tokenizer.texts_to_sequences(corpus)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:48.646897Z","iopub.execute_input":"2023-06-13T20:49:48.647662Z","iopub.status.idle":"2023-06-13T20:49:48.653731Z","shell.execute_reply.started":"2023-06-13T20:49:48.647500Z","shell.execute_reply":"2023-06-13T20:49:48.652890Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nlogest_in_train = max(train_tweets,key = lambda sen:len(word_tokenize(sen)))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:48.655112Z","iopub.execute_input":"2023-06-13T20:49:48.655480Z","iopub.status.idle":"2023-06-13T20:49:50.037496Z","shell.execute_reply.started":"2023-06-13T20:49:48.655445Z","shell.execute_reply":"2023-06-13T20:49:50.036550Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"logest_in_train","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:50.038830Z","iopub.execute_input":"2023-06-13T20:49:50.039272Z","iopub.status.idle":"2023-06-13T20:49:50.047181Z","shell.execute_reply.started":"2023-06-13T20:49:50.039240Z","shell.execute_reply":"2023-06-13T20:49:50.046141Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'if you have a son or a daughter would you like to see them going to a war with iran and come back in a body bag let the republicans know'"},"metadata":{}}]},{"cell_type":"code","source":"lenght_long_sen = len(word_tokenize(logest_in_train))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:50.048625Z","iopub.execute_input":"2023-06-13T20:49:50.049222Z","iopub.status.idle":"2023-06-13T20:49:50.056334Z","shell.execute_reply.started":"2023-06-13T20:49:50.049189Z","shell.execute_reply":"2023-06-13T20:49:50.055459Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"lenght_long_sen","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:50.057531Z","iopub.execute_input":"2023-06-13T20:49:50.058553Z","iopub.status.idle":"2023-06-13T20:49:50.068220Z","shell.execute_reply.started":"2023-06-13T20:49:50.058522Z","shell.execute_reply":"2023-06-13T20:49:50.067295Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"31"},"metadata":{}}]},{"cell_type":"code","source":"from keras.utils import pad_sequences\npaded_seq = pad_sequences(emd(train_tweets),lenght_long_sen,padding=\"post\")\npaded_for_test = pad_sequences(emd(test_tweets),lenght_long_sen,padding=\"post\")","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:50.069985Z","iopub.execute_input":"2023-06-13T20:49:50.070746Z","iopub.status.idle":"2023-06-13T20:49:50.298014Z","shell.execute_reply.started":"2023-06-13T20:49:50.070681Z","shell.execute_reply":"2023-06-13T20:49:50.297168Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import urllib.request\nurl = \"http://nlp.stanford.edu/data/glove.6B.zip\"\nloc = \"/kaggle/working/glove.6B.zip\"\n\nurllib.request.urlretrieve(url,loc)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:49:50.299208Z","iopub.execute_input":"2023-06-13T20:49:50.299530Z","iopub.status.idle":"2023-06-13T20:52:30.518165Z","shell.execute_reply.started":"2023-06-13T20:49:50.299500Z","shell.execute_reply":"2023-06-13T20:52:30.517202Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/glove.6B.zip', <http.client.HTTPMessage at 0x7bd112681810>)"},"metadata":{}}]},{"cell_type":"code","source":"import zipfile\n\nzip_file = \"/kaggle/working/glove.6B.zip\"\nextracted_dir = \"/kaggle/working/\"\n\nwith zipfile.ZipFile(zip_file,\"r\") as zip_ref:\n    zip_ref.extractall(extracted_dir)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:52:30.519710Z","iopub.execute_input":"2023-06-13T20:52:30.520330Z","iopub.status.idle":"2023-06-13T20:52:46.095088Z","shell.execute_reply.started":"2023-06-13T20:52:30.520295Z","shell.execute_reply":"2023-06-13T20:52:46.094020Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import os\ndir = \"/kaggle/working/\"\nfiles = os.listdir(dir)\n\nfor file in files:\n    if file.startswith(\"glove.6B\") and file.endswith(\".txt\"):\n        glove_file = os.path.join(dir,file)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:52:46.096646Z","iopub.execute_input":"2023-06-13T20:52:46.097316Z","iopub.status.idle":"2023-06-13T20:52:46.103134Z","shell.execute_reply.started":"2023-06-13T20:52:46.097278Z","shell.execute_reply":"2023-06-13T20:52:46.102242Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"glove_file","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:52:46.104475Z","iopub.execute_input":"2023-06-13T20:52:46.105184Z","iopub.status.idle":"2023-06-13T20:52:48.322251Z","shell.execute_reply.started":"2023-06-13T20:52:46.105153Z","shell.execute_reply":"2023-06-13T20:52:48.321212Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/glove.6B.100d.txt'"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nembeding_dict = dict()\nemdeding_dim = 200\nglove_file = open('/kaggle/working/glove.6B.200d.txt')\nfor line in glove_file:\n    records = line.split()\n    words = records[0]\n    vector_dim = np.asarray(records[1:],dtype=\"float32\")\n    embeding_dict[words] = vector_dim\nglove_file.close()    ","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:52:48.324573Z","iopub.execute_input":"2023-06-13T20:52:48.324972Z","iopub.status.idle":"2023-06-13T20:53:10.689622Z","shell.execute_reply.started":"2023-06-13T20:52:48.324933Z","shell.execute_reply":"2023-06-13T20:53:10.688646Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"embeding_matrix = np.zeros((vocab_lenght,emdeding_dim))\nfor word,index in word_tokenizer.word_index.items():\n    embeding_matrixd = embeding_dict.get(word)\n    if embeding_matrixd is not None:\n        embeding_matrix[index] = embeding_matrixd\nembeding_matrix.shape        ","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:53:10.691108Z","iopub.execute_input":"2023-06-13T20:53:10.691476Z","iopub.status.idle":"2023-06-13T20:53:10.777578Z","shell.execute_reply.started":"2023-06-13T20:53:10.691443Z","shell.execute_reply":"2023-06-13T20:53:10.776484Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(17228, 200)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(paded_seq,train_targets,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:53:10.778910Z","iopub.execute_input":"2023-06-13T20:53:10.779300Z","iopub.status.idle":"2023-06-13T20:53:10.791400Z","shell.execute_reply.started":"2023-06-13T20:53:10.779267Z","shell.execute_reply":"2023-06-13T20:53:10.789192Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.utils import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, GlobalMaxPool1D, BatchNormalization\nfrom keras.initializers import Constant\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:53:10.794885Z","iopub.execute_input":"2023-06-13T20:53:10.795166Z","iopub.status.idle":"2023-06-13T20:53:10.812682Z","shell.execute_reply.started":"2023-06-13T20:53:10.795121Z","shell.execute_reply":"2023-06-13T20:53:10.809582Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def bidiectinal_lstm():\n    model = Sequential()\n    model.add(Embedding(input_dim=embeding_matrix.shape[0], \n                        output_dim=embeding_matrix.shape[1], \n                        weights = [embeding_matrix], \n                        input_length=lenght_long_sen))\n    model.add(Bidirectional(LSTM(lenght_long_sen, return_sequences = True, recurrent_dropout=0.2)))\n    model.add(GlobalMaxPool1D())\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(lenght_long_sen, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(lenght_long_sen, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:53:10.818295Z","iopub.execute_input":"2023-06-13T20:53:10.819205Z","iopub.status.idle":"2023-06-13T20:53:10.827292Z","shell.execute_reply.started":"2023-06-13T20:53:10.819173Z","shell.execute_reply":"2023-06-13T20:53:10.826331Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model = bidiectinal_lstm()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:53:10.828787Z","iopub.execute_input":"2023-06-13T20:53:10.829626Z","iopub.status.idle":"2023-06-13T20:53:13.752892Z","shell.execute_reply.started":"2023-06-13T20:53:10.829595Z","shell.execute_reply":"2023-06-13T20:53:13.751864Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train,y_train,epochs = 10,validation_data=(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T21:05:41.204432Z","iopub.execute_input":"2023-06-13T21:05:41.204719Z","iopub.status.idle":"2023-06-13T21:06:22.222105Z","shell.execute_reply.started":"2023-06-13T21:05:41.204694Z","shell.execute_reply":"2023-06-13T21:06:22.221177Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Epoch 1/10\n191/191 [==============================] - 4s 18ms/step - loss: 0.2044 - accuracy: 0.9328 - val_loss: 0.9816 - val_accuracy: 0.6848\nEpoch 2/10\n191/191 [==============================] - 4s 20ms/step - loss: 0.1961 - accuracy: 0.9389 - val_loss: 0.5643 - val_accuracy: 0.7814\nEpoch 3/10\n191/191 [==============================] - 4s 21ms/step - loss: 0.1782 - accuracy: 0.9440 - val_loss: 0.8338 - val_accuracy: 0.7538\nEpoch 4/10\n191/191 [==============================] - 4s 20ms/step - loss: 0.1708 - accuracy: 0.9479 - val_loss: 0.8808 - val_accuracy: 0.7636\nEpoch 5/10\n191/191 [==============================] - 4s 19ms/step - loss: 0.1525 - accuracy: 0.9496 - val_loss: 0.8149 - val_accuracy: 0.7085\nEpoch 6/10\n191/191 [==============================] - 4s 20ms/step - loss: 0.1501 - accuracy: 0.9511 - val_loss: 0.8480 - val_accuracy: 0.7663\nEpoch 7/10\n191/191 [==============================] - 4s 19ms/step - loss: 0.1429 - accuracy: 0.9548 - val_loss: 0.7256 - val_accuracy: 0.7354\nEpoch 8/10\n191/191 [==============================] - 4s 19ms/step - loss: 0.1235 - accuracy: 0.9621 - val_loss: 0.9900 - val_accuracy: 0.7328\nEpoch 9/10\n191/191 [==============================] - 3s 18ms/step - loss: 0.1265 - accuracy: 0.9612 - val_loss: 1.3659 - val_accuracy: 0.7374\nEpoch 10/10\n191/191 [==============================] - 4s 20ms/step - loss: 0.1229 - accuracy: 0.9612 - val_loss: 1.0844 - val_accuracy: 0.7531\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7bcc69f95300>"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, TimeDistributed\nfrom tensorflow.keras.layers import Layer, Attention, Concatenate\n\nclass AttentionLayer(Layer):\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1), initializer=\"normal\")\n        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1), initializer=\"zeros\")\n        super(AttentionLayer, self).build(input_shape)\n\n    def call(self, x):\n        et = tf.keras.backend.squeeze(tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b), axis=-1)\n        at = tf.keras.backend.softmax(et)\n        at = tf.keras.backend.expand_dims(at, axis=-1)\n        output = x * at\n        return tf.keras.backend.sum(output, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0], input_shape[-1]\n\n# Input shape: (None, 31)\nsentence_input = Input(shape=(31,), dtype='int32')\n\n# Embedding layer\nembedding_dim = 100\nvocab_size = 10000\nsentence_embedded = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=31)(sentence_input)\n\n# Word level Bi-LSTM\nword_lstm = Bidirectional(LSTM(100, return_sequences=True))(sentence_embedded)\n\n# Attention layer at word level\nword_attention = AttentionLayer()(word_lstm)\n\n# Sentence level Bi-LSTM\nsentence_lstm = Bidirectional(LSTM(100, return_sequences=True))(word_lstm)\n\n# Attention layer at sentence level\nsentence_attention = AttentionLayer()(sentence_lstm)\n\n# Concatenate word attention and sentence attention\nsentence_rep = Concatenate()([word_attention, sentence_attention])\n\n# Output layer\noutput = Dense(1, activation='sigmoid')(sentence_rep)\n\n# Define the model\nmodel = Model(inputs=sentence_input, outputs=output)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:56:36.848575Z","iopub.execute_input":"2023-06-13T20:56:36.848957Z","iopub.status.idle":"2023-06-13T20:56:37.975054Z","shell.execute_reply.started":"2023-06-13T20:56:36.848928Z","shell.execute_reply":"2023-06-13T20:56:37.974038Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:56:38.475669Z","iopub.execute_input":"2023-06-13T20:56:38.476034Z","iopub.status.idle":"2023-06-13T20:56:38.490183Z","shell.execute_reply.started":"2023-06-13T20:56:38.476004Z","shell.execute_reply":"2023-06-13T20:56:38.489190Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Hierarchical Attention Networks ","metadata":{}},{"cell_type":"code","source":"model.fit(x_train,y_train,epochs = 10,validation_data=(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T20:56:38.750796Z","iopub.execute_input":"2023-06-13T20:56:38.751093Z","iopub.status.idle":"2023-06-13T20:59:07.577513Z","shell.execute_reply.started":"2023-06-13T20:56:38.751068Z","shell.execute_reply":"2023-06-13T20:59:07.576356Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch 1/10\n191/191 [==============================] - 85s 85ms/step - loss: 0.6114 - accuracy: 0.6519 - val_loss: 0.5064 - val_accuracy: 0.7571\nEpoch 2/10\n191/191 [==============================] - 7s 36ms/step - loss: 0.4178 - accuracy: 0.8146 - val_loss: 0.5190 - val_accuracy: 0.8004\nEpoch 3/10\n191/191 [==============================] - 4s 21ms/step - loss: 0.3396 - accuracy: 0.8570 - val_loss: 0.5252 - val_accuracy: 0.7932\nEpoch 4/10\n191/191 [==============================] - 3s 18ms/step - loss: 0.2957 - accuracy: 0.8814 - val_loss: 0.5057 - val_accuracy: 0.7925\nEpoch 5/10\n191/191 [==============================] - 3s 17ms/step - loss: 0.2616 - accuracy: 0.9028 - val_loss: 0.4936 - val_accuracy: 0.7787\nEpoch 6/10\n191/191 [==============================] - 4s 21ms/step - loss: 0.2382 - accuracy: 0.9122 - val_loss: 0.5890 - val_accuracy: 0.7768\nEpoch 7/10\n191/191 [==============================] - 4s 20ms/step - loss: 0.2135 - accuracy: 0.9232 - val_loss: 0.5938 - val_accuracy: 0.7722\nEpoch 8/10\n191/191 [==============================] - 5s 24ms/step - loss: 0.2005 - accuracy: 0.9281 - val_loss: 0.5901 - val_accuracy: 0.7663\nEpoch 9/10\n191/191 [==============================] - 4s 19ms/step - loss: 0.1854 - accuracy: 0.9342 - val_loss: 0.7351 - val_accuracy: 0.7643\nEpoch 10/10\n191/191 [==============================] - 4s 19ms/step - loss: 0.1705 - accuracy: 0.9394 - val_loss: 0.6460 - val_accuracy: 0.7426\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7bcc7038dd20>"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, Dropout, Dense\nfrom tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Conv1D\nfrom tensorflow.keras.layers import GlobalAveragePooling1D\n\ndef transformer_encoder(inputs, head_dim, num_heads, ff_dim, dropout=0):\n    attention = MultiHeadAttention(num_heads=num_heads, key_dim=head_dim)(inputs, inputs)\n    attention = Dropout(rate=dropout)(attention)\n    attention = LayerNormalization(epsilon=1e-6)(inputs + attention)\n\n    outputs = Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(attention)\n    outputs = Conv1D(filters=inputs.shape[-1], kernel_size=1)(outputs)\n    outputs = Dropout(rate=dropout)(outputs)\n    outputs = LayerNormalization(epsilon=1e-6)(attention + outputs)\n    return outputs\n\ndef transformer_model(input_shape, head_dim, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0):\n    inputs = Input(shape=input_shape)\n    \n    # Embedding layer\n    embedding_dim = 100\n    vocab_size = 10000\n    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_shape[0])(inputs)\n    \n    # Transformer Encoder blocks\n    for _ in range(num_transformer_blocks):\n        x = transformer_encoder(x, head_dim, num_heads, ff_dim, dropout)\n    \n    # Global average pooling and MLP\n    x = GlobalAveragePooling1D()(x)\n    for dim in mlp_units:\n        x = Dense(units=dim, activation=\"relu\")(x)\n        x = Dropout(rate=dropout)(x)\n    outputs = Dense(units=1, activation=\"sigmoid\")(x)\n    \n    # Create the model\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\n# Input shape: (None, 31)\ninput_shape = (31,)\nhead_dim = 64\nnum_heads = 4\nff_dim = 64\nnum_transformer_blocks = 4\nmlp_units = [128, 64]\ndropout = 0.1\n\n# Create the transformer model\nmodel = transformer_model(input_shape, head_dim, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T21:00:23.655260Z","iopub.execute_input":"2023-06-13T21:00:23.655639Z","iopub.status.idle":"2023-06-13T21:00:24.126166Z","shell.execute_reply.started":"2023-06-13T21:00:23.655609Z","shell.execute_reply":"2023-06-13T21:00:24.125185Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(x_train,y_train,epochs = 10,validation_data=(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T21:00:24.184835Z","iopub.execute_input":"2023-06-13T21:00:24.185170Z","iopub.status.idle":"2023-06-13T21:01:28.333977Z","shell.execute_reply.started":"2023-06-13T21:00:24.185121Z","shell.execute_reply":"2023-06-13T21:01:28.332952Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 1/10\n191/191 [==============================] - 26s 58ms/step - loss: 0.6996 - accuracy: 0.5456 - val_loss: 0.6824 - val_accuracy: 0.5732\nEpoch 2/10\n191/191 [==============================] - 6s 29ms/step - loss: 0.6866 - accuracy: 0.5677 - val_loss: 0.6825 - val_accuracy: 0.5732\nEpoch 3/10\n191/191 [==============================] - 5s 25ms/step - loss: 0.6861 - accuracy: 0.5675 - val_loss: 0.6829 - val_accuracy: 0.5732\nEpoch 4/10\n191/191 [==============================] - 4s 23ms/step - loss: 0.6855 - accuracy: 0.5691 - val_loss: 0.6839 - val_accuracy: 0.5732\nEpoch 5/10\n191/191 [==============================] - 5s 24ms/step - loss: 0.6853 - accuracy: 0.5695 - val_loss: 0.6825 - val_accuracy: 0.5732\nEpoch 6/10\n191/191 [==============================] - 4s 20ms/step - loss: 0.6853 - accuracy: 0.5696 - val_loss: 0.6825 - val_accuracy: 0.5732\nEpoch 7/10\n191/191 [==============================] - 4s 21ms/step - loss: 0.6866 - accuracy: 0.5685 - val_loss: 0.6828 - val_accuracy: 0.5732\nEpoch 8/10\n191/191 [==============================] - 4s 21ms/step - loss: 0.6870 - accuracy: 0.5616 - val_loss: 0.6868 - val_accuracy: 0.5732\nEpoch 9/10\n191/191 [==============================] - 4s 20ms/step - loss: 0.6844 - accuracy: 0.5691 - val_loss: 0.6826 - val_accuracy: 0.5732\nEpoch 10/10\n191/191 [==============================] - 3s 18ms/step - loss: 0.6849 - accuracy: 0.5711 - val_loss: 0.6824 - val_accuracy: 0.5732\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7bd0fc561120>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\nfrom tensorflow.keras.layers import GlobalMaxPool1D, BatchNormalization, Dropout, Activation\nfrom tensorflow.keras.layers import Multiply, Lambda\nimport tensorflow.keras.backend as K\n\ndef attention_layer(inputs):\n    # Calculate attention weights\n    attention_weights = Dense(1, activation='tanh')(inputs)\n    attention_weights = Activation('softmax')(attention_weights)\n    \n    # Apply attention weights to input sequences\n    weighted_inputs = Multiply()([inputs, attention_weights])\n    \n    return weighted_inputs\n\ndef bidiectinal_lstm_with_attention(embedding_matrix, lenght_long_sen):\n    model = Sequential()\n    model.add(Embedding(input_dim=embedding_matrix.shape[0], \n                        output_dim=embedding_matrix.shape[1], \n                        weights=[embedding_matrix], \n                        input_length=lenght_long_sen))\n    model.add(Bidirectional(LSTM(lenght_long_sen, return_sequences=True, recurrent_dropout=0.2), merge_mode='concat'))\n    \n    # Apply attention mechanism\n    model.add(Lambda(attention_layer))\n    \n    model.add(GlobalMaxPool1D())\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(lenght_long_sen, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(lenght_long_sen, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T21:04:27.706899Z","iopub.execute_input":"2023-06-13T21:04:27.707690Z","iopub.status.idle":"2023-06-13T21:04:27.721302Z","shell.execute_reply.started":"2023-06-13T21:04:27.707654Z","shell.execute_reply":"2023-06-13T21:04:27.720327Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(x_train,y_train,epochs = 10,validation_data=(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T21:04:40.713937Z","iopub.execute_input":"2023-06-13T21:04:40.714407Z","iopub.status.idle":"2023-06-13T21:05:41.201105Z","shell.execute_reply.started":"2023-06-13T21:04:40.714371Z","shell.execute_reply":"2023-06-13T21:05:41.200184Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Epoch 1/10\n191/191 [==============================] - 22s 57ms/step - loss: 0.6851 - accuracy: 0.5680 - val_loss: 0.6839 - val_accuracy: 0.5732\nEpoch 2/10\n191/191 [==============================] - 6s 29ms/step - loss: 0.6848 - accuracy: 0.5695 - val_loss: 0.6824 - val_accuracy: 0.5732\nEpoch 3/10\n191/191 [==============================] - 5s 26ms/step - loss: 0.6848 - accuracy: 0.5698 - val_loss: 0.6840 - val_accuracy: 0.5732\nEpoch 4/10\n191/191 [==============================] - 5s 24ms/step - loss: 0.6840 - accuracy: 0.5701 - val_loss: 0.6785 - val_accuracy: 0.5732\nEpoch 5/10\n191/191 [==============================] - 5s 24ms/step - loss: 0.6289 - accuracy: 0.6499 - val_loss: 0.6394 - val_accuracy: 0.6848\nEpoch 6/10\n191/191 [==============================] - 4s 21ms/step - loss: 0.4678 - accuracy: 0.7984 - val_loss: 0.4674 - val_accuracy: 0.8063\nEpoch 7/10\n191/191 [==============================] - 4s 19ms/step - loss: 0.3806 - accuracy: 0.8499 - val_loss: 0.4750 - val_accuracy: 0.7978\nEpoch 8/10\n191/191 [==============================] - 4s 19ms/step - loss: 0.3157 - accuracy: 0.8810 - val_loss: 0.4998 - val_accuracy: 0.7814\nEpoch 9/10\n191/191 [==============================] - 4s 19ms/step - loss: 0.2651 - accuracy: 0.9094 - val_loss: 0.6789 - val_accuracy: 0.7511\nEpoch 10/10\n191/191 [==============================] - 4s 20ms/step - loss: 0.2350 - accuracy: 0.9238 - val_loss: 0.7598 - val_accuracy: 0.7479\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7bd0f176aaa0>"},"metadata":{}}]},{"cell_type":"code","source":"preds = model.predict(x_test)\npreds = preds.round()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T21:12:48.157821Z","iopub.execute_input":"2023-06-13T21:12:48.158274Z","iopub.status.idle":"2023-06-13T21:12:48.946222Z","shell.execute_reply.started":"2023-06-13T21:12:48.158235Z","shell.execute_reply":"2023-06-13T21:12:48.945203Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"48/48 [==============================] - 1s 4ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"ss = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\nss[\"target\"] = model.predict(paded_for_test)\nss[\"target\"] = ss['target'].apply(lambda x: 1 if x > 0.5 else 0)\nss.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T21:13:59.041262Z","iopub.execute_input":"2023-06-13T21:13:59.042314Z","iopub.status.idle":"2023-06-13T21:13:59.587276Z","shell.execute_reply.started":"2023-06-13T21:13:59.042267Z","shell.execute_reply":"2023-06-13T21:13:59.586199Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"102/102 [==============================] - 0s 4ms/step\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       0\n1   2       1\n2   3       1\n3   9       1\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"ss.to_csv(\"attn_model.csv\", index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T21:14:10.804575Z","iopub.execute_input":"2023-06-13T21:14:10.805309Z","iopub.status.idle":"2023-06-13T21:14:10.819954Z","shell.execute_reply.started":"2023-06-13T21:14:10.805247Z","shell.execute_reply":"2023-06-13T21:14:10.819084Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}